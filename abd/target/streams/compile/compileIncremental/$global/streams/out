[0m[[0mdebug[0m] [0m[naha] [0m
[0m[[0mdebug[0m] [0m[naha] Initial source changes: [0m
[0m[[0mdebug[0m] [0m[naha] 	removed:Set()[0m
[0m[[0mdebug[0m] [0m[naha] 	added: Set(/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala, /home/janthe/Bureau/abd/src/main/scala/example/Hello.scala)[0m
[0m[[0mdebug[0m] [0m[naha] 	modified: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated products: Set()[0m
[0m[[0mdebug[0m] [0m[naha] External API changes: API Changes: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Modified binary dependencies: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Initial directly invalidated sources: Set(/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala, /home/janthe/Bureau/abd/src/main/scala/example/Hello.scala)[0m
[0m[[0mdebug[0m] [0m[naha] [0m
[0m[[0mdebug[0m] [0m[naha] Sources indirectly invalidated by:[0m
[0m[[0mdebug[0m] [0m[naha] 	product: Set()[0m
[0m[[0mdebug[0m] [0m[naha] 	binary dep: Set()[0m
[0m[[0mdebug[0m] [0m[naha] 	external source: Set()[0m
[0m[[0mdebug[0m] [0mAll initially invalidated sources: Set(/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala, /home/janthe/Bureau/abd/src/main/scala/example/Hello.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala, /home/janthe/Bureau/abd/src/main/scala/example/Hello.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Recompiling all 2 sources: invalidated sources (2) exceeded 50.0% of all sources[0m
[0m[[0minfo[0m] [0mCompiling 2 Scala sources to /home/janthe/Bureau/abd/target/scala-2.12/classes...[0m
[0m[[0mdebug[0m] [0mGetting org.scala-sbt:compiler-interface:0.13.13:component from component compiler for Scala 2.12.1[0m
[0m[[0mdebug[0m] [0mGetting org.scala-sbt:compiler-interface:0.13.13:component from component compiler for Scala 2.12.1[0m
[0m[[0mdebug[0m] [0mRunning cached compiler 2ae0573b, interfacing (CompilerInterface) with Scala compiler version 2.12.1[0m
[0m[[0mdebug[0m] [0mCalling Scala compiler with arguments  (CompilerInterface):[0m
[0m[[0mdebug[0m] [0m	-bootclasspath[0m
[0m[[0mdebug[0m] [0m	/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes:/home/janthe/.ivy2/cache/org.scala-lang/scala-library/jars/scala-library-2.12.1.jar[0m
[0m[[0mdebug[0m] [0m	-classpath[0m
[0m[[0mdebug[0m] [0m	/home/janthe/Bureau/abd/target/scala-2.12/classes[0m
[0m[[31merror[0m] [0m/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala:1: object apache is not a member of package org[0m
[0m[[31merror[0m] [0mimport org.apache.spark.SparkContext[0m
[0m[[31merror[0m] [0m           ^[0m
[0m[[31merror[0m] [0m/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala:2: object apache is not a member of package org[0m
[0m[[31merror[0m] [0mimport org.apache.spark.SparkContext._[0m
[0m[[31merror[0m] [0m           ^[0m
[0m[[31merror[0m] [0m/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala:3: object apache is not a member of package org[0m
[0m[[31merror[0m] [0mimport org.apache.spark.SparkConf[0m
[0m[[31merror[0m] [0m           ^[0m
[0m[[31merror[0m] [0m/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala:9: not found: type SparkConf[0m
[0m[[31merror[0m] [0m    val conf = new SparkConf().setAppName("Simple Application")[0m
[0m[[31merror[0m] [0m                   ^[0m
[0m[[31merror[0m] [0m/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala:10: not found: type SparkContext[0m
[0m[[31merror[0m] [0m    val sc = new SparkContext(conf)[0m
[0m[[31merror[0m] [0m                 ^[0m
[0m[[31merror[0m] [0m/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala:17: not found: value spark[0m
[0m[[31merror[0m] [0m    val result = spark.sparkContext.parallelize(0 until rectangleNumber, slices).map { i =>[0m
[0m[[31merror[0m] [0m                 ^[0m
[0m[[31merror[0m] [0m/home/janthe/Bureau/abd/src/main/scala/SparkIntegral.scala:23: not found: value spark[0m
[0m[[31merror[0m] [0m    spark.stop()[0m
[0m[[31merror[0m] [0m    ^[0m
[0m[[31merror[0m] [0m7 errors found[0m
[0m[[0mdebug[0m] [0mCompilation failed (CompilerInterface)[0m
[0m[[31merror[0m] [0m(compile:[31mcompileIncremental[0m) Compilation failed[0m
